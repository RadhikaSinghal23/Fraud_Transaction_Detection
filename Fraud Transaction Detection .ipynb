{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "072ebe75",
   "metadata": {},
   "source": [
    "## Identifying Credit Card Fraud Transactions\n",
    "\n",
    "The dataset chosen is a split of train test data from the credit card transactions of a labeled dataset. The objective is to build a model to flag a fraud transaction in the future. This project realises the importance of data pre-processing, feature engineering, handling imabalnced classes through SMOTE, BOrderline SVM SMOTE and compare performance, apply classification models (Random Forest, Gradient Boost Trees), feature importance, hyper-parameter tuning through Bayesian Optimization with HYPEROPT, select appropriate evaluation metric (F1 score, AUC ROC, G-Mean)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f031965c",
   "metadata": {},
   "source": [
    "##### The following assumptions are listed below which are made to keep the analysis: \n",
    "1. The dataset is a simulated version. The credit card numbers are assumed to be 10 characters long.\n",
    "2. street, zip and city name were found to be unique to the full name of the customer hence, only one column, out of the four is required \n",
    "3. There is one and only one person with a complete full name, that is each full name is unique and represents only one customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1b0a625",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import os \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d60bf51",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\".../fraudTrain.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad12250",
   "metadata": {},
   "source": [
    "### Data Overview and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1b5a373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1048575 entries, 0 to 1048574\n",
      "Data columns (total 21 columns):\n",
      " #   Column                 Non-Null Count    Dtype  \n",
      "---  ------                 --------------    -----  \n",
      " 0   trans_date_trans_time  1048575 non-null  object \n",
      " 1   trans_time             1048575 non-null  object \n",
      " 2   cc_num                 1048575 non-null  int64  \n",
      " 3   merchant               1048575 non-null  object \n",
      " 4   category               1048575 non-null  object \n",
      " 5   amt                    1048575 non-null  float64\n",
      " 6   first                  1048575 non-null  object \n",
      " 7   last                   1048575 non-null  object \n",
      " 8   gender                 1048575 non-null  object \n",
      " 9   street                 1048575 non-null  object \n",
      " 10  city                   1048575 non-null  object \n",
      " 11  state                  1048575 non-null  object \n",
      " 12  zip                    1048575 non-null  int64  \n",
      " 13  city_pop               1048575 non-null  int64  \n",
      " 14  job                    1048575 non-null  object \n",
      " 15  dob                    1048575 non-null  object \n",
      " 16  trans_num              1048575 non-null  object \n",
      " 17  unix_time              1048575 non-null  int64  \n",
      " 18  extracted_time         1048575 non-null  object \n",
      " 19  duration_trans         1048575 non-null  object \n",
      " 20  is_fraud               1048575 non-null  int64  \n",
      "dtypes: float64(1), int64(5), object(15)\n",
      "memory usage: 168.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4ccd2fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trans_date_trans_time</th>\n",
       "      <th>trans_time</th>\n",
       "      <th>cc_num</th>\n",
       "      <th>merchant</th>\n",
       "      <th>category</th>\n",
       "      <th>amt</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>gender</th>\n",
       "      <th>street</th>\n",
       "      <th>...</th>\n",
       "      <th>state</th>\n",
       "      <th>zip</th>\n",
       "      <th>city_pop</th>\n",
       "      <th>job</th>\n",
       "      <th>dob</th>\n",
       "      <th>trans_num</th>\n",
       "      <th>unix_time</th>\n",
       "      <th>extracted_time</th>\n",
       "      <th>duration_trans</th>\n",
       "      <th>is_fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01-01-2019</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>270000000</td>\n",
       "      <td>fraud_Rippin, Kub and Mann</td>\n",
       "      <td>misc_net</td>\n",
       "      <td>4.97</td>\n",
       "      <td>Jennifer</td>\n",
       "      <td>Banks</td>\n",
       "      <td>F</td>\n",
       "      <td>561 Perry Cove</td>\n",
       "      <td>...</td>\n",
       "      <td>NC</td>\n",
       "      <td>28654</td>\n",
       "      <td>3495</td>\n",
       "      <td>Psychologist, counselling</td>\n",
       "      <td>09-03-1988</td>\n",
       "      <td>0b242abb623afc578575680df30655b9</td>\n",
       "      <td>1325376018</td>\n",
       "      <td>00:18</td>\n",
       "      <td>00:00:18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01-01-2019</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>630000000</td>\n",
       "      <td>fraud_Heller, Gutmann and Zieme</td>\n",
       "      <td>grocery_pos</td>\n",
       "      <td>107.23</td>\n",
       "      <td>Stephanie</td>\n",
       "      <td>Gill</td>\n",
       "      <td>F</td>\n",
       "      <td>43039 Riley Greens Suite 393</td>\n",
       "      <td>...</td>\n",
       "      <td>WA</td>\n",
       "      <td>99160</td>\n",
       "      <td>149</td>\n",
       "      <td>Special educational needs teacher</td>\n",
       "      <td>21-06-1978</td>\n",
       "      <td>1f76529f8574734946361c461b024d99</td>\n",
       "      <td>1325376044</td>\n",
       "      <td>00:44</td>\n",
       "      <td>00:00:44</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01-01-2019</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>389000000</td>\n",
       "      <td>fraud_Lind-Buckridge</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>220.11</td>\n",
       "      <td>Edward</td>\n",
       "      <td>Sanchez</td>\n",
       "      <td>M</td>\n",
       "      <td>594 White Dale Suite 530</td>\n",
       "      <td>...</td>\n",
       "      <td>ID</td>\n",
       "      <td>83252</td>\n",
       "      <td>4154</td>\n",
       "      <td>Nature conservation officer</td>\n",
       "      <td>19-01-1962</td>\n",
       "      <td>a1a22d70485983eac12b5b88dad1cf95</td>\n",
       "      <td>1325376051</td>\n",
       "      <td>00:51</td>\n",
       "      <td>00:00:51</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01-01-2019</td>\n",
       "      <td>00:01:00</td>\n",
       "      <td>353000000</td>\n",
       "      <td>fraud_Kutch, Hermiston and Farrell</td>\n",
       "      <td>gas_transport</td>\n",
       "      <td>45.00</td>\n",
       "      <td>Jeremy</td>\n",
       "      <td>White</td>\n",
       "      <td>M</td>\n",
       "      <td>9443 Cynthia Court Apt. 038</td>\n",
       "      <td>...</td>\n",
       "      <td>MT</td>\n",
       "      <td>59632</td>\n",
       "      <td>1939</td>\n",
       "      <td>Patent attorney</td>\n",
       "      <td>12-01-1967</td>\n",
       "      <td>6b849c168bdad6f867558c3793159a81</td>\n",
       "      <td>1325376076</td>\n",
       "      <td>01:16</td>\n",
       "      <td>00:00:16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01-01-2019</td>\n",
       "      <td>00:03:00</td>\n",
       "      <td>376000000</td>\n",
       "      <td>fraud_Keeling-Crist</td>\n",
       "      <td>misc_pos</td>\n",
       "      <td>41.96</td>\n",
       "      <td>Tyler</td>\n",
       "      <td>Garcia</td>\n",
       "      <td>M</td>\n",
       "      <td>408 Bradley Rest</td>\n",
       "      <td>...</td>\n",
       "      <td>VA</td>\n",
       "      <td>24433</td>\n",
       "      <td>99</td>\n",
       "      <td>Dance movement psychotherapist</td>\n",
       "      <td>28-03-1986</td>\n",
       "      <td>a41d7549acf90789359a9aa5346dcb46</td>\n",
       "      <td>1325376186</td>\n",
       "      <td>03:06</td>\n",
       "      <td>00:00:06</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  trans_date_trans_time trans_time     cc_num  \\\n",
       "0            01-01-2019   00:00:00  270000000   \n",
       "1            01-01-2019   00:00:00  630000000   \n",
       "2            01-01-2019   00:00:00  389000000   \n",
       "3            01-01-2019   00:01:00  353000000   \n",
       "4            01-01-2019   00:03:00  376000000   \n",
       "\n",
       "                             merchant       category     amt      first  \\\n",
       "0          fraud_Rippin, Kub and Mann       misc_net    4.97   Jennifer   \n",
       "1     fraud_Heller, Gutmann and Zieme    grocery_pos  107.23  Stephanie   \n",
       "2                fraud_Lind-Buckridge  entertainment  220.11     Edward   \n",
       "3  fraud_Kutch, Hermiston and Farrell  gas_transport   45.00     Jeremy   \n",
       "4                 fraud_Keeling-Crist       misc_pos   41.96      Tyler   \n",
       "\n",
       "      last gender                        street  ... state    zip  city_pop  \\\n",
       "0    Banks      F                561 Perry Cove  ...    NC  28654      3495   \n",
       "1     Gill      F  43039 Riley Greens Suite 393  ...    WA  99160       149   \n",
       "2  Sanchez      M      594 White Dale Suite 530  ...    ID  83252      4154   \n",
       "3    White      M   9443 Cynthia Court Apt. 038  ...    MT  59632      1939   \n",
       "4   Garcia      M              408 Bradley Rest  ...    VA  24433        99   \n",
       "\n",
       "                                 job         dob  \\\n",
       "0          Psychologist, counselling  09-03-1988   \n",
       "1  Special educational needs teacher  21-06-1978   \n",
       "2        Nature conservation officer  19-01-1962   \n",
       "3                    Patent attorney  12-01-1967   \n",
       "4     Dance movement psychotherapist  28-03-1986   \n",
       "\n",
       "                          trans_num   unix_time  extracted_time  \\\n",
       "0  0b242abb623afc578575680df30655b9  1325376018           00:18   \n",
       "1  1f76529f8574734946361c461b024d99  1325376044           00:44   \n",
       "2  a1a22d70485983eac12b5b88dad1cf95  1325376051           00:51   \n",
       "3  6b849c168bdad6f867558c3793159a81  1325376076           01:16   \n",
       "4  a41d7549acf90789359a9aa5346dcb46  1325376186           03:06   \n",
       "\n",
       "  duration_trans is_fraud  \n",
       "0       00:00:18        0  \n",
       "1       00:00:44        0  \n",
       "2       00:00:51        0  \n",
       "3       00:00:16        0  \n",
       "4       00:00:06        0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a774507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0             Jennifer_Banks\n",
      "1             Stephanie_Gill\n",
      "2             Edward_Sanchez\n",
      "3               Jeremy_White\n",
      "4               Tyler_Garcia\n",
      "                 ...        \n",
      "1048570         Haley_Wagner\n",
      "1048571    Meredith_Campbell\n",
      "1048572          Susan_Mills\n",
      "1048573           Julia_Bell\n",
      "1048574     Shannon_Williams\n",
      "Name: full_name, Length: 1048575, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#concatenating column 'first' and 'last' to create a new column 'full name'\n",
    "df['full_name']= df['first']+'_'+df['last']\n",
    "print(df['full_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e812c6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "full_name        956\n",
       "zip              952\n",
       "state             51\n",
       "city             879\n",
       "street           965\n",
       "trans_num    1048575\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#it can be observed that the doesnt have any null values. #finding out the unique values for the columns\n",
    "df[['full_name','zip','state','city','street','trans_num']].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b87ceb28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#dropping columns that are unnecessary\n",
    "df = df.drop(['street','city','zip','city_pop','unix_time','extracted_time','first','last'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e61fbf53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1048575, 14)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dropping any duplicates in case\n",
    "df.drop_duplicates(inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e5941d",
   "metadata": {},
   "source": [
    "No duplicates were found in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea9ba38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting necessary columns to datetime\n",
    "from datetime import datetime\n",
    "df['trans_date_trans_time'] = pd.to_datetime(df['trans_date_trans_time'])\n",
    "df.rename({'trans_date_trans_time':'transaction_date'},  axis=1, inplace = True)\n",
    "df['dob'] = pd.to_datetime(df['dob'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "485aa342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          31.0\n",
      "1          41.0\n",
      "2          57.0\n",
      "3          52.0\n",
      "4          33.0\n",
      "           ... \n",
      "1048570    76.0\n",
      "1048571    20.0\n",
      "1048572    67.0\n",
      "1048573    29.0\n",
      "1048574    22.0\n",
      "Name: age, Length: 1048575, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#creating an age column with reference to 2020\n",
    "now = pd.to_datetime('2020-01-01')\n",
    "df['dob'] = df['dob'].where(df['dob'] < now, df['dob'] -  np.timedelta64(100, 'Y'))\n",
    "df['age'] = (now - df['dob']).astype('<m8[Y]') \n",
    "df = df.drop(['dob'],axis=1)\n",
    "print(df['age'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f62082",
   "metadata": {},
   "source": [
    "feature scaling for numeric variable: check if min max is closer, then scale "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6dad75",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7b8fdb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1042569\n",
      "1       6006\n",
      "Name: is_fraud, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#checking the number of fraud labels\n",
    "fraud_perc = df['is_fraud'].value_counts()\n",
    "print(fraud_perc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bb240a",
   "metadata": {},
   "source": [
    "the class is highly imbalanced "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9d83995",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plotting correlation matrix with features to check their importance\n",
    "cor = df.corr()\n",
    "fig = plt.figure(figsize = (12, 9))\n",
    "sns.heatmap(cor, vmax = .8, square = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3cdd5f",
   "metadata": {},
   "source": [
    "The relationship of amount and fraud label is much higher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ca8a4a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#checking the number of fraud labels\n",
    "fraud = df[df['is_fraud'] == 1]\n",
    "valid = df[df['is_fraud'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a72dece1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    6006.000000\n",
       "mean      530.573492\n",
       "std       391.333069\n",
       "min         1.180000\n",
       "25%       241.577500\n",
       "50%       391.165000\n",
       "75%       901.950000\n",
       "max      1371.810000\n",
       "Name: amt, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking fraud and amt\n",
    "fraud.amt.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "89d28887",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.042569e+06\n",
       "mean     6.762744e+01\n",
       "std      1.536956e+02\n",
       "min      1.000000e+00\n",
       "25%      9.600000e+00\n",
       "50%      4.722000e+01\n",
       "75%      8.247000e+01\n",
       "max      2.894890e+04\n",
       "Name: amt, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking valid and amt\n",
    "valid.amt.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af63aa0b",
   "metadata": {},
   "source": [
    "#other gradient decent based algos and distance based (KNN, KMeans, SVM) can also be applied but would also require feature scaling ** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1259b79e",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc6d2b6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction_date</th>\n",
       "      <th>trans_time</th>\n",
       "      <th>cc_num</th>\n",
       "      <th>merchant</th>\n",
       "      <th>category</th>\n",
       "      <th>amt</th>\n",
       "      <th>gender</th>\n",
       "      <th>state</th>\n",
       "      <th>job</th>\n",
       "      <th>trans_num</th>\n",
       "      <th>duration_trans</th>\n",
       "      <th>is_fraud</th>\n",
       "      <th>full_name</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>514</td>\n",
       "      <td>8</td>\n",
       "      <td>397</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>370</td>\n",
       "      <td>45701</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>409</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>215</td>\n",
       "      <td>241</td>\n",
       "      <td>4</td>\n",
       "      <td>10623</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>428</td>\n",
       "      <td>128847</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>852</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "      <td>390</td>\n",
       "      <td>0</td>\n",
       "      <td>21891</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>307</td>\n",
       "      <td>662104</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>293</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>360</td>\n",
       "      <td>2</td>\n",
       "      <td>4400</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>328</td>\n",
       "      <td>440259</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>428</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>66</td>\n",
       "      <td>297</td>\n",
       "      <td>9</td>\n",
       "      <td>4096</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>116</td>\n",
       "      <td>672104</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>917</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048570</th>\n",
       "      <td>429</td>\n",
       "      <td>967</td>\n",
       "      <td>207</td>\n",
       "      <td>166</td>\n",
       "      <td>5</td>\n",
       "      <td>7600</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>286294</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>343</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048571</th>\n",
       "      <td>429</td>\n",
       "      <td>967</td>\n",
       "      <td>160</td>\n",
       "      <td>110</td>\n",
       "      <td>9</td>\n",
       "      <td>11594</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>211</td>\n",
       "      <td>786716</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>666</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048572</th>\n",
       "      <td>429</td>\n",
       "      <td>968</td>\n",
       "      <td>199</td>\n",
       "      <td>456</td>\n",
       "      <td>6</td>\n",
       "      <td>2027</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>175</td>\n",
       "      <td>97489</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>871</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048573</th>\n",
       "      <td>429</td>\n",
       "      <td>968</td>\n",
       "      <td>141</td>\n",
       "      <td>620</td>\n",
       "      <td>5</td>\n",
       "      <td>852</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>193</td>\n",
       "      <td>379398</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>495</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048574</th>\n",
       "      <td>429</td>\n",
       "      <td>968</td>\n",
       "      <td>8</td>\n",
       "      <td>83</td>\n",
       "      <td>9</td>\n",
       "      <td>581</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>351</td>\n",
       "      <td>577841</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>832</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1048575 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         transaction_date  trans_time  cc_num  merchant  category    amt  \\\n",
       "0                       0           0      22       514         8    397   \n",
       "1                       0           0     215       241         4  10623   \n",
       "2                       0           0      77       390         0  21891   \n",
       "3                       0           1      45       360         2   4400   \n",
       "4                       0           3      66       297         9   4096   \n",
       "...                   ...         ...     ...       ...       ...    ...   \n",
       "1048570               429         967     207       166         5   7600   \n",
       "1048571               429         967     160       110         9  11594   \n",
       "1048572               429         968     199       456         6   2027   \n",
       "1048573               429         968     141       620         5    852   \n",
       "1048574               429         968       8        83         9    581   \n",
       "\n",
       "         gender  state  job  trans_num  duration_trans  is_fraud  full_name  \\\n",
       "0             0     27  370      45701              18         0        409   \n",
       "1             0     47  428     128847              44         0        852   \n",
       "2             1     13  307     662104              51         0        293   \n",
       "3             1     26  328     440259              16         0        428   \n",
       "4             1     45  116     672104               6         0        917   \n",
       "...         ...    ...  ...        ...             ...       ...        ...   \n",
       "1048570       0     20    2     286294              29         0        343   \n",
       "1048571       0     12  211     786716              50         0        666   \n",
       "1048572       0     17  175      97489              31         0        871   \n",
       "1048573       0     34  193     379398              38         0        495   \n",
       "1048574       0     10  351     577841              50         0        832   \n",
       "\n",
       "         age  \n",
       "0         16  \n",
       "1         26  \n",
       "2         42  \n",
       "3         37  \n",
       "4         18  \n",
       "...      ...  \n",
       "1048570   61  \n",
       "1048571    5  \n",
       "1048572   52  \n",
       "1048573   14  \n",
       "1048574    7  \n",
       "\n",
       "[1048575 rows x 14 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import label encoder \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Encode labels\n",
    "df = df.apply(LabelEncoder().fit_transform)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1272a1",
   "metadata": {},
   "source": [
    "### Train Test Split \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "368acfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = df.drop(['is_fraud'], axis = 1)\n",
    "y = df['is_fraud']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff77a64",
   "metadata": {},
   "source": [
    "### Handing Imbalanced Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f6de49",
   "metadata": {},
   "source": [
    "#### SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b908f303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 729810, 1: 4192})\n",
      "Counter({0: 729810, 1: 729810})\n"
     ]
    }
   ],
   "source": [
    "#Performing SMOTE\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# summarize class distribution\n",
    "print(Counter(y_train))\n",
    "\n",
    "# define undersample strategy\n",
    "SMOTE = SMOTE()\n",
    "\n",
    "# fit and apply the transform\n",
    "X_train_SMOTE, y_train_SMOTE = SMOTE.fit_resample(X_train, y_train)\n",
    "\n",
    "# summarize class distribution\n",
    "print(Counter(y_train_SMOTE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228db142",
   "metadata": {},
   "source": [
    "#### Borderline SVM SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "997f7f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 729794, 1: 4208})\n",
      "Counter({0: 729794, 1: 729794})\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SVMSMOTE\n",
    "# summarize class distribution\n",
    "print(Counter(y_train))\n",
    "sm = SVMSMOTE()\n",
    "# fit and apply the transform\n",
    "X_train_sm, y_train_sm = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "# summarize class distribution\n",
    "print(Counter(y_train_sm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fd112d",
   "metadata": {},
   "source": [
    "#### ADAYSN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f612a131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 729794, 1: 4208})\n",
      "Counter({0: 729794, 1: 729391})\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import ADASYN\n",
    "\n",
    "# summarize class distribution\n",
    "print(Counter(y_train))\n",
    "ad = ADASYN()\n",
    "# fit and apply the transform\n",
    "X_train_ad, y_train_ad = ad.fit_resample(X_train, y_train)\n",
    "\n",
    "# summarize class distribution\n",
    "print(Counter(y_train_ad))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cdc9dd4",
   "metadata": {},
   "source": [
    "the best performing method out of the three can be chosen while evaluating performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941cafcb",
   "metadata": {},
   "source": [
    "## Fitting into the model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6674abd",
   "metadata": {},
   "source": [
    "#### Random Forest (SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d83d01b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for oversampled SMOTE data:                precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    312759\n",
      "           1       0.64      0.81      0.72      1814\n",
      "\n",
      "    accuracy                           1.00    314573\n",
      "   macro avg       0.82      0.90      0.86    314573\n",
      "weighted avg       1.00      1.00      1.00    314573\n",
      "\n",
      "ROC AUC score for oversampled SMOTE data:  0.902510420532151\n",
      "ROC AUC score for (baseline) data:  0.8590823043832605\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import classification_report, roc_auc_score, f1_score\n",
    "\n",
    "#defing the model \n",
    "model= RandomForestClassifier()\n",
    "\n",
    "#using SMOTE for fitting\n",
    "clf_SMOTE = model.fit(X_train_SMOTE, y_train_SMOTE)\n",
    "pred_SMOTE = clf_SMOTE.predict(X_test)\n",
    "\n",
    "#baseline dataset for fitting\n",
    "clf = model.fit(X_train, y_train)\n",
    "pred= clf.predict(X_test)\n",
    "\n",
    "print(\"Classification report for oversampled SMOTE data: \", classification_report(y_test, pred_SMOTE))\n",
    "print(\"ROC AUC score for oversampled SMOTE data: \", roc_auc_score(y_test, pred_SMOTE))\n",
    "print(\"ROC AUC score for (baseline) data: \", roc_auc_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672861e2",
   "metadata": {},
   "source": [
    "#### Random Forest (SMOTE SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "78dce981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for oversampled SMOTE data:                precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    312775\n",
      "           1       0.70      0.80      0.75      1798\n",
      "\n",
      "    accuracy                           1.00    314573\n",
      "   macro avg       0.85      0.90      0.87    314573\n",
      "weighted avg       1.00      1.00      1.00    314573\n",
      "\n",
      "ROC AUC score for oversampled SMOTE data:  0.8978156637064834\n",
      "ROC AUC score for (baseline) data:  0.8639596220954037\n"
     ]
    }
   ],
   "source": [
    "model= RandomForestClassifier()\n",
    "clf_sm = model.fit(X_train_sm, y_train_sm)\n",
    "pred_sm = clf_sm.predict(X_test)\n",
    "\n",
    "print(\"Classification report for oversampled SMOTE data: \", classification_report(y_test, pred_sm))\n",
    "print(\"ROC AUC score for oversampled SMOTE data: \", roc_auc_score(y_test, pred_sm))\n",
    "print(\"ROC AUC score for (baseline) data: \", roc_auc_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb1814d",
   "metadata": {},
   "source": [
    "#### XGB Trees (SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9d0b87ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for oversampled SMOTE data:                precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00    312759\n",
      "           1       0.44      0.86      0.58      1814\n",
      "\n",
      "    accuracy                           0.99    314573\n",
      "   macro avg       0.72      0.93      0.79    314573\n",
      "weighted avg       1.00      0.99      0.99    314573\n",
      "\n",
      "ROC AUC score for oversampled SMOTE data:  0.9292739289033369\n",
      "ROC AUC score for (baseline) data:  0.9045235392699253\n"
     ]
    }
   ],
   "source": [
    "#how do you identify max_depth - XGBClassifier(max_depth = 4)\n",
    "from xgboost import XGBClassifier\n",
    "model = XGBClassifier()\n",
    "\n",
    "#using SMOTE for fitting\n",
    "clf_SMOTE = model.fit(X_train_SMOTE, y_train_SMOTE)\n",
    "pred_SMOTE = clf_SMOTE.predict(X_test)\n",
    "\n",
    "#baseline dataset for fitting\n",
    "clf = model.fit(X_train, y_train)\n",
    "pred= clf.predict(X_test)\n",
    "\n",
    "print(\"Classification report for oversampled SMOTE data: \", classification_report(y_test, pred_SMOTE))\n",
    "print(\"ROC AUC score for oversampled SMOTE data: \", roc_auc_score(y_test, pred_SMOTE))\n",
    "print(\"ROC AUC score for (baseline) data: \", roc_auc_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a6db0a",
   "metadata": {},
   "source": [
    "#### XGB ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e48cb0df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for oversampled SMOTE data:                precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00    312775\n",
      "           1       0.39      0.86      0.53      1798\n",
      "\n",
      "    accuracy                           0.99    314573\n",
      "   macro avg       0.69      0.93      0.77    314573\n",
      "weighted avg       1.00      0.99      0.99    314573\n",
      "\n",
      "ROC AUC score for oversampled SMOTE data:  0.9276677084788301\n",
      "ROC AUC score for (baseline) data:  0.9064669320141768\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "#using SMOTE for fitting\n",
    "clf_ad = xgb.fit(X_train_ad, y_train_ad)\n",
    "pred_ad = clf_ad.predict(X_test)\n",
    "\n",
    "print(\"Classification report for oversampled SMOTE data: \", classification_report(y_test, pred_ad))\n",
    "print(\"ROC AUC score for oversampled SMOTE data: \", roc_auc_score(y_test, pred_ad))\n",
    "print(\"ROC AUC score for (baseline) data: \", roc_auc_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df61c43",
   "metadata": {},
   "source": [
    "Since the models above are giving similar scores for SMOTE, Borderline SVM SMOTE and ADASYN, it could be good to go with naive SMOTE due to lesser compution time. Also, xgb gives better results than rf, so we cont with the model and aim to improve it. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a36960",
   "metadata": {},
   "source": [
    "### Getting feature importance from xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "453edd64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#get feature importances from the model\n",
    "headers = [\"name\", \"score\"]\n",
    "values = sorted(zip(X_train.columns, xgb.feature_importances_), key=lambda x: x[1] * -1)\n",
    "xgb_feature_importances = pd.DataFrame(values, columns = headers)\n",
    "\n",
    "#plot feature importances\n",
    "x_pos = np.arange(0, len(xgb_feature_importances))\n",
    "plt.bar(x_pos, xgb_feature_importances['score'])\n",
    "plt.xticks(x_pos, xgb_feature_importances['name'])\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Feature importances (XGB)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f495198",
   "metadata": {},
   "source": [
    "The most important feature identified are amount transacted, category transacted for, gender of transactioner and transaction time taken"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4194eb",
   "metadata": {},
   "source": [
    "### Hyper Paramter Tuning for the best fit model - xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "85d165bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize domain space for range of values\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "\n",
    "space={'max_depth': hp.quniform(\"max_depth\", 3, 18, 1),\n",
    "        'gamma': hp.uniform ('gamma', 1,9),\n",
    "        'reg_alpha' : hp.quniform('reg_alpha', 40,180,1),\n",
    "        'reg_lambda' : hp.uniform('reg_lambda', 0,1),\n",
    "        'colsample_bytree' : hp.uniform('colsample_bytree', 0.5,1),\n",
    "        'min_child_weight' : hp.quniform('min_child_weight', 0, 10, 1),\n",
    "        'n_estimators': 180,\n",
    "        'seed': 0\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "df3676f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define objective function\n",
    "\n",
    "def objective(space):\n",
    "    model=XGBClassifier(\n",
    "                    n_estimators =space['n_estimators'], max_depth = int(space['max_depth']), gamma = space['gamma'],\n",
    "                    reg_alpha = int(space['reg_alpha']),min_child_weight=int(space['min_child_weight']),\n",
    "                    colsample_bytree=int(space['colsample_bytree']))\n",
    "    \n",
    "      \n",
    "    model.fit(X_train_SMOTE, y_train_SMOTE)\n",
    "    pred = model.predict(X_test)\n",
    "    roc_auc = roc_auc_score(y_test, pred>0.5)\n",
    "    print (\"SCORE:\", roc_auc)\n",
    "    return {'loss': -roc_auc, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f001398a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                                                                 \n",
      "0.8718508535625469                                                                                                     \n",
      "SCORE:                                                                                                                 \n",
      "0.8735885928725324                                                                                                     \n",
      "SCORE:                                                                                                                 \n",
      "0.8779721889231359                                                                                                     \n",
      "SCORE:                                                                                                                 \n",
      "0.8721748887675175                                                                                                     \n",
      "SCORE:                                                                                                                 \n",
      "0.8743528129061775                                                                                                     \n",
      "SCORE:                                                                                                                 \n",
      "0.8733944100270739                                                                                                     \n",
      "SCORE:                                                                                                                 \n",
      "0.8749054469441754                                                                                                     \n",
      "SCORE:                                                                                                                 \n",
      "0.8719609511149655                                                                                                     \n",
      "SCORE:                                                                                                                 \n",
      "0.873425971129833                                                                                                      \n",
      "SCORE:                                                                                                                 \n",
      "0.8738036498959892                                                                                                     \n",
      "SCORE:                                                                                                                 \n",
      "0.8737424241306139                                                                                                     \n",
      "SCORE:                                                                                                                 \n",
      "0.8726824643479477                                                                                                     \n",
      "SCORE:                                                                                                                 \n",
      "0.8730963630759103                                                                                                     \n",
      "SCORE:                                                                                                                 \n",
      "0.8745525001402548                                                                                                     \n",
      "SCORE:                                                                                                                 \n",
      "0.8713600169781628                                                                                                     \n",
      "SCORE:                                                                                                                 \n",
      "0.8748432147229904                                                                                                     \n",
      "SCORE:                                                                                                                 \n",
      "0.8712645806062189                                                                                                     \n",
      "SCORE:                                                                                                                 \n",
      "0.8729324165813062                                                                                                     \n",
      "SCORE:                                                                                                                 \n",
      "0.8733178829326521                                                                                                     \n",
      "SCORE:                                                                                                                 \n",
      "0.8714197810709667                                                                                                     \n",
      "SCORE:                                                                                                                 \n",
      "0.8781287826001217                                                                                                     \n",
      "SCORE:                                                                                                                 \n",
      "0.8779578015839944                                                                                                     \n",
      "SCORE:                                                                                                                 \n",
      "0.8784037406370493                                                                                                     \n",
      "SCORE:                                                                                                                 \n",
      "0.8785203694830863                                                                                                     \n",
      "SCORE:                                                                                                                 \n",
      "0.8726035171362883                                                                                                     \n",
      "SCORE:                                                                                                                 \n",
      "0.8751020739124432                                                                                                     \n",
      "SCORE:                                                                                                                 \n",
      "0.872147644222139                                                                                                      \n",
      "SCORE:                                                                                                                 \n",
      "0.8744100884214105                                                                                                     \n",
      "SCORE:                                                                                                                 \n",
      "0.8724453248660645                                                                                                     \n",
      "SCORE:                                                                                                                 \n",
      "0.874469920974548                                                                                                      \n",
      "SCORE:                                                                                                                 \n",
      "0.8753243468328517                                                                                                     \n",
      "SCORE:                                                                                                                 \n",
      "0.8725376325118656                                                                                                     \n",
      "SCORE:                                                                                                                 \n",
      "0.8770819778705974                                                                                                     \n",
      "SCORE:                                                                                                                 \n",
      "0.8732662487267046                                                                                                     \n",
      "SCORE:                                                                                                                 \n",
      "0.8732171030983279                                                                                                     \n",
      "SCORE:                                                                                                                 \n",
      "0.8726464053123796                                                                                                     \n",
      "SCORE:                                                                                                                 \n",
      "0.8758101137961887                                                                                                     \n",
      "SCORE:                                                                                                                 \n",
      "0.8749538155033136                                                                                                     \n",
      "SCORE:                                                                                                                 \n",
      "0.8727307884523243                                                                                                     \n",
      "SCORE:                                                                                                                 \n",
      "0.8743963172252689                                                                                                     \n",
      "SCORE:                                                                                                                 \n",
      "0.8733930852751692                                                                                                     \n",
      "SCORE:                                                                                                                 \n",
      "0.873076563814055                                                                                                      \n",
      "SCORE:                                                                                                                 \n",
      "0.8786690386542158                                                                                                     \n",
      "SCORE:                                                                                                                 \n",
      "0.875476007809457                                                                                                      \n",
      "SCORE:                                                                                                                 \n",
      "0.8752975815098063                                                                                                     \n",
      "SCORE:                                                                                                                 \n",
      "0.8740786079329167                                                                                                     \n",
      "SCORE:                                                                                                                 \n",
      "0.8726323602749048                                                                                                     \n",
      "SCORE:                                                                                                                 \n",
      "0.8748417770559904                                                                                                     \n",
      "SCORE:                                                                                                                 \n",
      "0.8740316325860161                                                                                                     \n",
      "SCORE:                                                                                                                 \n",
      "0.8742142829771424                                                                                                     \n",
      "100%|███████████████████████████████████████████████| 50/50 [55:47<00:00, 66.94s/trial, best loss: -0.8786690386542158]\n"
     ]
    }
   ],
   "source": [
    "#optimisation\n",
    "\n",
    "trials = Trials()\n",
    "\n",
    "best_hyperparams = fmin(fn = objective,\n",
    "                        space = space,\n",
    "                        algo = tpe.suggest,\n",
    "                        max_evals = 50,\n",
    "                        trials = trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a29706b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best hyperparameters are :  \n",
      "\n",
      "{'colsample_bytree': 0.868387742357372, 'gamma': 5.687858426453555, 'max_depth': 3.0, 'min_child_weight': 10.0, 'reg_alpha': 151.0, 'reg_lambda': 0.9450231907635458}\n"
     ]
    }
   ],
   "source": [
    "#printing best hyperparameters \n",
    "print(\"The best hyperparameters are : \",\"\\n\")\n",
    "print(best_hyperparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4113dc2",
   "metadata": {},
   "source": [
    "### Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f31494a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for oversampled SMOTE data:                precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99    312759\n",
      "           1       0.16      0.89      0.28      1814\n",
      "\n",
      "    accuracy                           0.97    314573\n",
      "   macro avg       0.58      0.93      0.63    314573\n",
      "weighted avg       0.99      0.97      0.98    314573\n",
      "\n",
      "ROC AUC score for oversampled SMOTE data:  0.9319853522379703\n",
      "ROC AUC score for (baseline) data:  0.7657837378427067\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "tuned = XGBClassifier(max_depth = 3, gamma = 5.68, reg_alpha = 151,min_child_weight=10,\n",
    "                    colsample_bytree=0.86)\n",
    "\n",
    "#using SMOTE for fitting\n",
    "clf_SMOTE = tuned.fit(X_train_SMOTE, y_train_SMOTE)\n",
    "pred_SMOTE = clf_SMOTE.predict(X_test)\n",
    "\n",
    "#baseline dataset for fitting\n",
    "clf = tuned.fit(X_train, y_train)\n",
    "pred= clf.predict(X_test)\n",
    "\n",
    "print(\"Classification report for oversampled SMOTE data: \", classification_report(y_test, pred_SMOTE))\n",
    "print(\"ROC AUC score for oversampled SMOTE data: \", roc_auc_score(y_test, pred_SMOTE))\n",
    "print(\"ROC AUC score for (baseline) data: \", roc_auc_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7b2334",
   "metadata": {},
   "source": [
    "##### END NOTE: XGB model post hyper-parameter tuning with the simple SMOTE over-sampling technique gives the best results with a ROC_AUC score of 93% as opposed to 76% from the baseline data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
